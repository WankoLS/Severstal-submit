{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras.layers.convolutional import Conv2DTranspose\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import UpSampling2D, Conv2D, Activation, Input, Dropout, MaxPooling2D, Input\n",
    "from keras import Model\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "#change path to train and test images\n",
    "train_path = './train_images/'\n",
    "test_path = './test_images/'\n",
    "\n",
    "\n",
    "tr = pd.read_csv('train.csv')\n",
    "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RLE decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(rle, imgshape):\n",
    "    width = imgshape[0]\n",
    "    height= imgshape[1]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "def keras_generator(batch_size):\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for i in range(batch_size):            \n",
    "            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n",
    "            img = cv2.imread(train_path+fn)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n",
    "            \n",
    "            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n",
    "            \n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            mask = cv2.resize(mask, (img_size, img_size))\n",
    "            \n",
    "            x_batch += [img]\n",
    "            y_batch += [mask]\n",
    "                                    \n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        yield x_batch, np.expand_dims(y_batch, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize ResNet model with ImageNet weights and compile it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wanko\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"up...)`\n",
      "  \n",
      "W0908 00:10:45.255834 16644 deprecation_wrapper.py:119] From C:\\Users\\wanko\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0908 00:10:45.267805 16644 deprecation.py:323] From C:\\Users\\wanko\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "weights = 'resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "img_shape = (256,256,3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = ResNet50(weights=weights, input_shape=img_shape, include_top=False,\n",
    "                     input_tensor=img_input, classes=None)\n",
    "base_out = base_model.output\n",
    "\n",
    "up = Conv2D(1, (1,1), strides=(1, 1))(base_out)\n",
    "up = UpSampling2D(size=(32, 32), interpolation='bilinear')(up)\n",
    "\n",
    "\n",
    "model = Model(input=base_model.input, output=up)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(adam, 'binary_crossentropy')\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model and submit predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model.fit_generator(keras_generator(batch_size),\n",
    "              steps_per_epoch=100,\n",
    "              epochs=20\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b2b1d361254761a2a4a06a2852ef26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testfiles=os.listdir(test_path)\n",
    "\n",
    "test_img = []\n",
    "for fn in tqdm_notebook(testfiles):\n",
    "        img = cv2.imread( test_path+fn )\n",
    "        img = cv2.resize(img,(img_size,img_size))       \n",
    "        test_img.append(img)\n",
    "        \n",
    "\n",
    "predict = model.predict(np.asarray(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    tmp = np.rot90( np.flipud( img ), k=3 )\n",
    "    rle = []\n",
    "    lastColor = 0;\n",
    "    startpos = 0\n",
    "    endpos = 0\n",
    "\n",
    "    tmp = tmp.reshape(-1,1)   \n",
    "    for i in range( len(tmp) ):\n",
    "        if (lastColor==0) and tmp[i]>0:\n",
    "            startpos = i\n",
    "            lastColor = 1\n",
    "        elif (lastColor==1)and(tmp[i]==0):\n",
    "            endpos = i-1\n",
    "            lastColor = 0\n",
    "            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n",
    "    return \" \".join(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rle = []\n",
    "for img in tqdm_notebook(predict):      \n",
    "    img = cv2.resize(img, (1600, 256))\n",
    "    tmp = np.copy(img)\n",
    "    tmp[tmp<np.mean(img)] = 0\n",
    "    tmp[tmp>0] = 1\n",
    "    pred_rle.append(mask2rle(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv( 'sample_submission.csv' )\n",
    "for fn, rle in zip(testfiles, pred_rle):\n",
    "    sub['EncodedPixels'][sub['ImageId_ClassId'].apply(lambda x: x.split('_')[0]) == fn] = rle\n",
    "    \n",
    "img_s = cv2.imread( test_path + sub['ImageId_ClassId'][16].split('_')[0])\n",
    "mask_s = rle2mask(sub['EncodedPixels'][16], (256, 1600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
